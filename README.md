# facial Emotion Recognition
**Motivation**
Exploring the presence of emotional intelligent systems in everyday life has led to an increase in systems that learn and employ the understanding of emotions and feelings. For instance, systems that detect user’s feelings and improve their experience can be helpful to users when doing a mental health assessment, in a learning context, or even in an adaptive media system. Our project is in search of expanding this intelligent emotion recognition by creating a real-time facial emotion recognition system from a webcam, that will classify emotional states like happy/sad/angry/surprised and based on the state of emotion will perform triggering (like playing music or displaying content).
**Project Goals**
•	Implement real-time face and emotion detection using a webcam. 
•	Complete facial expression classification utilizing pre-trained CNN models (FER-2013, for example). 
•	Trigger action (i.e. actions like playing songs or showing motivational quotes) based on each emotion. 
•	Create an interactive display using PyGame. 
**Project Approach**
We'll primarily use Python. For face detection and the webcam, we'll use OpenCV. For emotion classification, we will use CNN models with TensorFlow/Keras, and potentially some pre-trained models (e.g., FER-2013). We can also test DeepFace or FaceRecognition libraries for accuracy scores. We will use the PyGame library to deal with actions based on the person's detected emotion, for the task at hand - e.g., playing music or showing motivational content in real-time.
**Project Outcome**
•	Functional real-time emotion recognition system.
•	Webcam-based face detection and emotion classification.
•	Emotion-triggered media control (audio/text).
•	Presentation and complete documentation.
